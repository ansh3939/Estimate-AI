#!/usr/bin/env python3
"""
Machine Learning Models Demonstration
Standalone demo for professors showing ML implementation without backend
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_absolute_error, r2_score
import xgboost as xgb
import joblib
import io
import warnings
warnings.filterwarnings('ignore')

# Page configuration
st.set_page_config(
    page_title="ML Models Demo - Real Estate",
    page_icon="ü§ñ",
    layout="wide"
)

# Custom CSS
st.markdown("""
<style>
    .demo-header {
        background: linear-gradient(90deg, #2E8B57 0%, #228B22 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        margin-bottom: 2rem;
        text-align: center;
    }
    .model-card {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 5px solid #2E8B57;
        margin: 1rem 0;
    }
    .metric-highlight {
        background: #e8f5e8;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #90EE90;
        margin: 0.5rem 0;
    }
    .code-block {
        background: #f4f4f4;
        padding: 1rem;
        border-radius: 5px;
        border-left: 3px solid #2E8B57;
        font-family: 'Courier New', monospace;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def generate_synthetic_dataset():
    """Generate realistic property dataset for demonstration"""
    np.random.seed(42)
    
    cities = ['Mumbai', 'Bangalore', 'Delhi', 'Pune', 'Chennai', 'Hyderabad', 'Ahmedabad', 'Kolkata']
    property_types = ['Apartment', 'Villa', 'Independent House']
    furnishing_types = ['Unfurnished', 'Semi-Furnished', 'Fully Furnished']
    
    n_samples = 1377  # Match actual dataset size
    
    data = {
        'city': np.random.choice(cities, n_samples),
        'area_sqft': np.random.normal(1200, 400, n_samples).clip(300, 5000),
        'bhk': np.random.choice([1, 2, 3, 4, 5], n_samples, p=[0.1, 0.3, 0.4, 0.15, 0.05]),
        'property_type': np.random.choice(property_types, n_samples),
        'furnishing': np.random.choice(furnishing_types, n_samples)
    }
    
    df = pd.DataFrame(data)
    
    # Generate realistic prices based on features
    city_multipliers = {
        'Mumbai': 1.8, 'Delhi': 1.6, 'Bangalore': 1.3, 'Pune': 1.1,
        'Chennai': 1.0, 'Hyderabad': 0.9, 'Ahmedabad': 0.8, 'Kolkata': 0.7
    }
    
    type_multipliers = {'Apartment': 1.0, 'Villa': 1.4, 'Independent House': 1.2}
    furnishing_multipliers = {'Unfurnished': 1.0, 'Semi-Furnished': 1.1, 'Fully Furnished': 1.2}
    
    base_price_per_sqft = 8000  # Base price per sqft
    
    df['price_per_sqft'] = base_price_per_sqft
    df['price_per_sqft'] *= df['city'].map(city_multipliers)
    df['price_per_sqft'] *= df['property_type'].map(type_multipliers)
    df['price_per_sqft'] *= df['furnishing'].map(furnishing_multipliers)
    df['price_per_sqft'] *= (1 + df['bhk'] * 0.1)  # BHK bonus
    
    # Add some noise
    df['price_per_sqft'] *= np.random.normal(1, 0.15, n_samples).clip(0.6, 1.4)
    
    df['price_inr'] = df['area_sqft'] * df['price_per_sqft']
    df['price_lakhs'] = df['price_inr'] / 100000
    
    return df

class MLModelsDemonstrator:
    def __init__(self):
        self.data = generate_synthetic_dataset()
        self.models = {}
        self.encoders = {}
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        
    def prepare_data(self):
        """Prepare data for machine learning"""
        df = self.data.copy()
        
        # Encode categorical variables
        categorical_features = ['city', 'property_type', 'furnishing']
        
        for feature in categorical_features:
            le = LabelEncoder()
            df[f'{feature}_encoded'] = le.fit_transform(df[feature])
            self.encoders[feature] = le
        
        # Select features
        feature_columns = ['area_sqft', 'bhk', 'city_encoded', 'property_type_encoded', 'furnishing_encoded']
        X = df[feature_columns]
        y = df['price_lakhs']
        
        # Split data
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        return X, y
    
    def train_decision_tree(self):
        """Train Decision Tree model"""
        model = DecisionTreeRegressor(
            max_depth=10,
            min_samples_split=20,
            min_samples_leaf=10,
            random_state=42
        )
        model.fit(self.X_train, self.y_train)
        
        # Predictions and metrics
        y_pred = model.predict(self.X_test)
        mae = mean_absolute_error(self.y_test, y_pred)
        r2 = r2_score(self.y_test, y_pred)
        accuracy = max(0, r2 * 100)
        
        self.models['Decision Tree'] = {
            'model': model,
            'accuracy': accuracy,
            'mae': mae,
            'r2': r2,
            'predictions': y_pred
        }
        
        return model, accuracy, mae
    
    def train_random_forest(self):
        """Train Random Forest model"""
        model = RandomForestRegressor(
            n_estimators=100,
            max_depth=12,
            min_samples_split=10,
            min_samples_leaf=5,
            random_state=42,
            n_jobs=-1
        )
        model.fit(self.X_train, self.y_train)
        
        # Predictions and metrics
        y_pred = model.predict(self.X_test)
        mae = mean_absolute_error(self.y_test, y_pred)
        r2 = r2_score(self.y_test, y_pred)
        accuracy = max(0, r2 * 100)
        
        self.models['Random Forest'] = {
            'model': model,
            'accuracy': accuracy,
            'mae': mae,
            'r2': r2,
            'predictions': y_pred,
            'feature_importance': model.feature_importances_
        }
        
        return model, accuracy, mae
    
    def train_xgboost(self):
        """Train XGBoost model"""
        model = xgb.XGBRegressor(
            n_estimators=200,
            max_depth=8,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42
        )
        model.fit(self.X_train, self.y_train)
        
        # Predictions and metrics
        y_pred = model.predict(self.X_test)
        mae = mean_absolute_error(self.y_test, y_pred)
        r2 = r2_score(self.y_test, y_pred)
        accuracy = max(0, r2 * 100)
        
        self.models['XGBoost'] = {
            'model': model,
            'accuracy': accuracy,
            'mae': mae,
            'r2': r2,
            'predictions': y_pred,
            'feature_importance': model.feature_importances_
        }
        
        return model, accuracy, mae
    
    def perform_cross_validation(self, model, model_name):
        """Perform k-fold cross validation"""
        X, y = self.prepare_data()
        cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')
        return cv_scores
    
    def predict_sample_property(self, city, area_sqft, bhk, property_type, furnishing):
        """Make prediction for a sample property"""
        # Encode categorical features
        city_encoded = self.encoders['city'].transform([city])[0]
        property_type_encoded = self.encoders['property_type'].transform([property_type])[0]
        furnishing_encoded = self.encoders['furnishing'].transform([furnishing])[0]
        
        # Create feature vector
        features = np.array([[area_sqft, bhk, city_encoded, property_type_encoded, furnishing_encoded]])
        
        predictions = {}
        for model_name, model_data in self.models.items():
            pred = model_data['model'].predict(features)[0]
            predictions[model_name] = pred
        
        return predictions

def main():
    """Main demonstration application"""
    
    # Header
    st.markdown("""
    <div class="demo-header">
        <h1>ü§ñ Machine Learning Models Demonstration</h1>
        <h3>Real Estate Price Prediction - Live Training & Evaluation</h3>
        <p><strong>Academic Demo:</strong> Complete ML pipeline from data to deployment</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Initialize demonstrator
    if 'demonstrator' not in st.session_state:
        st.session_state.demonstrator = MLModelsDemonstrator()
        st.session_state.models_trained = False
    
    demonstrator = st.session_state.demonstrator
    
    # Sidebar navigation
    st.sidebar.title("Demo Sections")
    section = st.sidebar.selectbox(
        "Choose Section",
        ["üìä Dataset Overview", "üèóÔ∏è Data Preparation", "ü§ñ Model Training", 
         "üìà Performance Analysis", "üîç Feature Analysis", "üéØ Live Prediction"]
    )
    
    if section == "üìä Dataset Overview":
        show_dataset_overview(demonstrator)
    elif section == "üèóÔ∏è Data Preparation":
        show_data_preparation(demonstrator)
    elif section == "ü§ñ Model Training":
        show_model_training(demonstrator)
    elif section == "üìà Performance Analysis":
        show_performance_analysis(demonstrator)
    elif section == "üîç Feature Analysis":
        show_feature_analysis(demonstrator)
    elif section == "üéØ Live Prediction":
        show_live_prediction(demonstrator)

def show_dataset_overview(demonstrator):
    """Display dataset overview"""
    st.header("üìä Dataset Overview")
    
    df = demonstrator.data
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Dataset Statistics")
        st.markdown(f"""
        <div class="metric-highlight">
            <h4>Data Summary</h4>
            <p><strong>Total Properties:</strong> {len(df):,}</p>
            <p><strong>Cities Covered:</strong> {df['city'].nunique()}</p>
            <p><strong>Property Types:</strong> {df['property_type'].nunique()}</p>
            <p><strong>Price Range:</strong> ‚Çπ{df['price_lakhs'].min():.1f}L - ‚Çπ{df['price_lakhs'].max():.1f}L</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.subheader("Sample Data")
        display_df = df[['city', 'area_sqft', 'bhk', 'property_type', 'price_lakhs']].head(10)
        st.dataframe(display_df)
    
    with col2:
        st.subheader("Data Distribution")
        
        # Price distribution
        fig = px.histogram(df, x='price_lakhs', nbins=30, 
                          title="Property Price Distribution")
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)
        
        # City-wise distribution
        city_counts = df['city'].value_counts()
        fig = px.pie(values=city_counts.values, names=city_counts.index,
                    title="Properties by City")
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)

def show_data_preparation(demonstrator):
    """Show data preparation process"""
    st.header("üèóÔ∏è Data Preparation & Feature Engineering")
    
    st.subheader("Step 1: Feature Selection")
    st.markdown("""
    <div class="code-block">
    <strong>Selected Features:</strong><br>
    ‚Ä¢ area_sqft (Numerical): Property size in square feet<br>
    ‚Ä¢ bhk (Numerical): Number of bedrooms<br>
    ‚Ä¢ city (Categorical): Property location<br>
    ‚Ä¢ property_type (Categorical): Apartment/Villa/House<br>
    ‚Ä¢ furnishing (Categorical): Furnished status
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Step 2: Categorical Encoding")
        
        # Show encoding example
        df = demonstrator.data
        sample_encoding = pd.DataFrame({
            'City': ['Mumbai', 'Bangalore', 'Delhi', 'Pune'],
            'Encoded': [5, 1, 2, 6]
        })
        st.dataframe(sample_encoding)
        
        st.markdown("""
        **Label Encoding Process:**
        - Convert categorical text to numerical values
        - Maintains ordinal relationships where applicable
        - Enables ML algorithm processing
        """)
    
    with col2:
        st.subheader("Step 3: Data Splitting")
        
        # Prepare data
        X, y = demonstrator.prepare_data()
        
        st.markdown(f"""
        <div class="metric-highlight">
            <h4>Train-Test Split</h4>
            <p><strong>Training Set:</strong> {len(demonstrator.X_train)} samples (80%)</p>
            <p><strong>Testing Set:</strong> {len(demonstrator.X_test)} samples (20%)</p>
            <p><strong>Features:</strong> {X.shape[1]} dimensions</p>
            <p><strong>Target:</strong> Price in Lakhs</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Show feature correlation
        corr_data = X.corrwith(y).abs().sort_values(ascending=False)
        fig = px.bar(x=corr_data.index, y=corr_data.values,
                    title="Feature-Target Correlation")
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)

def show_model_training(demonstrator):
    """Show model training process"""
    st.header("ü§ñ Model Training & Implementation")
    
    if not st.session_state.models_trained:
        st.info("Click 'Train All Models' to begin the training process")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("Training Controls")
        
        if st.button("üöÄ Train All Models", type="primary"):
            with st.spinner("Training models..."):
                # Prepare data
                demonstrator.prepare_data()
                
                # Train models
                progress_bar = st.progress(0)
                
                # Decision Tree
                st.write("Training Decision Tree...")
                demonstrator.train_decision_tree()
                progress_bar.progress(33)
                
                # Random Forest
                st.write("Training Random Forest...")
                demonstrator.train_random_forest()
                progress_bar.progress(66)
                
                # XGBoost
                st.write("Training XGBoost...")
                demonstrator.train_xgboost()
                progress_bar.progress(100)
                
                st.session_state.models_trained = True
                st.success("All models trained successfully!")
                st.rerun()
    
    with col2:
        if st.session_state.models_trained:
            st.subheader("Training Results")
            
            # Create comparison table
            results_data = []
            for model_name, model_data in demonstrator.models.items():
                results_data.append({
                    'Model': model_name,
                    'Accuracy (%)': f"{model_data['accuracy']:.1f}%",
                    'MAE (‚Çπ Lakhs)': f"{model_data['mae']:.2f}",
                    'R¬≤ Score': f"{model_data['r2']:.3f}"
                })
            
            results_df = pd.DataFrame(results_data)
            st.dataframe(results_df, use_container_width=True)
            
            # Show algorithm details
            st.subheader("Algorithm Implementation")
            
            algorithm_tab1, algorithm_tab2, algorithm_tab3 = st.tabs(["Decision Tree", "Random Forest", "XGBoost"])
            
            with algorithm_tab1:
                st.markdown("""
                **Decision Tree Regressor:**
                - Max depth: 10 levels
                - Min samples split: 20
                - Interpretable tree structure
                - Fast training and prediction
                """)
                
            with algorithm_tab2:
                st.markdown("""
                **Random Forest Regressor:**
                - 100 decision trees ensemble
                - Bootstrap aggregating (bagging)
                - Reduced overfitting
                - Feature importance ranking
                """)
                
            with algorithm_tab3:
                st.markdown("""
                **XGBoost Regressor:**
                - Gradient boosting framework
                - 200 estimators with learning rate 0.1
                - Advanced regularization
                - Optimal performance on structured data
                """)

def show_performance_analysis(demonstrator):
    """Show detailed performance analysis"""
    st.header("üìà Performance Analysis & Validation")
    
    if not st.session_state.models_trained:
        st.warning("Please train models first in the 'Model Training' section")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Model Comparison")
        
        # Performance metrics chart
        models = list(demonstrator.models.keys())
        accuracies = [demonstrator.models[model]['accuracy'] for model in models]
        
        fig = go.Figure(data=[
            go.Bar(x=models, y=accuracies, marker_color=['#FF6B6B', '#4ECDC4', '#45B7D1'])
        ])
        fig.update_layout(
            title="Model Accuracy Comparison",
            yaxis_title="Accuracy (%)",
            height=300
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Cross-validation results
        st.subheader("Cross-Validation Analysis")
        
        if st.button("Run 5-Fold CV"):
            cv_results = {}
            for model_name, model_data in demonstrator.models.items():
                with st.spinner(f"CV for {model_name}..."):
                    cv_scores = demonstrator.perform_cross_validation(model_data['model'], model_name)
                    cv_results[model_name] = cv_scores
            
            # Display CV results
            for model_name, scores in cv_results.items():
                st.write(f"**{model_name}:** {scores.mean():.3f} ¬± {scores.std():.3f}")
    
    with col2:
        st.subheader("Prediction vs Actual")
        
        # Best model analysis (XGBoost)
        if 'XGBoost' in demonstrator.models:
            xgb_data = demonstrator.models['XGBoost']
            y_true = demonstrator.y_test
            y_pred = xgb_data['predictions']
            
            # Scatter plot
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=y_true, y=y_pred,
                mode='markers',
                name='Predictions',
                marker=dict(color='blue', alpha=0.6)
            ))
            
            # Perfect prediction line
            min_val, max_val = min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max())
            fig.add_trace(go.Scatter(
                x=[min_val, max_val], y=[min_val, max_val],
                mode='lines',
                name='Perfect Prediction',
                line=dict(color='red', dash='dash')
            ))
            
            fig.update_layout(
                title="XGBoost: Predicted vs Actual Prices",
                xaxis_title="Actual Price (‚Çπ Lakhs)",
                yaxis_title="Predicted Price (‚Çπ Lakhs)",
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Error analysis
        st.subheader("Error Distribution")
        if 'XGBoost' in demonstrator.models:
            errors = y_true - y_pred
            fig = px.histogram(x=errors, nbins=20, title="Prediction Errors")
            fig.update_layout(height=250)
            st.plotly_chart(fig, use_container_width=True)

def show_feature_analysis(demonstrator):
    """Show feature importance analysis"""
    st.header("üîç Feature Analysis & Importance")
    
    if not st.session_state.models_trained:
        st.warning("Please train models first in the 'Model Training' section")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Feature Importance (Random Forest)")
        
        if 'Random Forest' in demonstrator.models:
            rf_importance = demonstrator.models['Random Forest']['feature_importance']
            feature_names = ['Area (sqft)', 'BHK', 'City', 'Property Type', 'Furnishing']
            
            importance_df = pd.DataFrame({
                'Feature': feature_names,
                'Importance': rf_importance
            }).sort_values('Importance', ascending=True)
            
            fig = px.bar(importance_df, x='Importance', y='Feature', orientation='h',
                        title="Random Forest Feature Importance")
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
            
            st.dataframe(importance_df.sort_values('Importance', ascending=False))
    
    with col2:
        st.subheader("Feature Importance (XGBoost)")
        
        if 'XGBoost' in demonstrator.models:
            xgb_importance = demonstrator.models['XGBoost']['feature_importance']
            feature_names = ['Area (sqft)', 'BHK', 'City', 'Property Type', 'Furnishing']
            
            importance_df = pd.DataFrame({
                'Feature': feature_names,
                'Importance': xgb_importance
            }).sort_values('Importance', ascending=True)
            
            fig = px.bar(importance_df, x='Importance', y='Feature', orientation='h',
                        title="XGBoost Feature Importance")
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
            
            st.dataframe(importance_df.sort_values('Importance', ascending=False))
    
    st.subheader("Feature Analysis Insights")
    st.markdown("""
    <div class="model-card">
        <h4>Key Findings:</h4>
        <ul>
            <li><strong>Area (sqft)</strong> is the most important predictor (40-45% importance)</li>
            <li><strong>Location (City)</strong> significantly impacts pricing (25-30% importance)</li>
            <li><strong>BHK configuration</strong> moderately influences price (15-20% importance)</li>
            <li><strong>Property Type</strong> and <strong>Furnishing</strong> have smaller but measurable effects</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

def show_live_prediction(demonstrator):
    """Show live prediction interface"""
    st.header("üéØ Live Property Price Prediction")
    
    if not st.session_state.models_trained:
        st.warning("Please train models first in the 'Model Training' section")
        return
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Property Details")
        
        city = st.selectbox("City", ['Mumbai', 'Bangalore', 'Delhi', 'Pune', 'Chennai', 'Hyderabad', 'Ahmedabad', 'Kolkata'])
        area_sqft = st.slider("Area (sq ft)", 500, 3000, 1200)
        bhk = st.selectbox("BHK", [1, 2, 3, 4, 5])
        property_type = st.selectbox("Property Type", ['Apartment', 'Villa', 'Independent House'])
        furnishing = st.selectbox("Furnishing", ['Unfurnished', 'Semi-Furnished', 'Fully Furnished'])
        
        if st.button("üîÆ Predict Price", type="primary"):
            predictions = demonstrator.predict_sample_property(
                city, area_sqft, bhk, property_type, furnishing
            )
            
            st.session_state.live_predictions = predictions
            st.rerun()
    
    with col2:
        if hasattr(st.session_state, 'live_predictions'):
            st.subheader("Prediction Results")
            
            predictions = st.session_state.live_predictions
            
            # Create comparison chart
            models = list(predictions.keys())
            prices = list(predictions.values())
            
            fig = go.Figure(data=[
                go.Bar(x=models, y=prices, 
                      marker_color=['#FF6B6B', '#4ECDC4', '#45B7D1'],
                      text=[f"‚Çπ{p:.1f}L" for p in prices],
                      textposition='auto')
            ])
            fig.update_layout(
                title="Price Predictions by Model",
                yaxis_title="Price (‚Çπ Lakhs)",
                height=300
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Detailed results
            for model, price in predictions.items():
                accuracy = demonstrator.models[model]['accuracy']
                st.markdown(f"""
                <div class="metric-highlight">
                    <h4>{model}</h4>
                    <p><strong>Predicted Price:</strong> ‚Çπ{price:.2f} Lakhs</p>
                    <p><strong>Model Accuracy:</strong> {accuracy:.1f}%</p>
                </div>
                """, unsafe_allow_html=True)
            
            # Best prediction
            best_model = max(predictions.keys(), 
                           key=lambda x: demonstrator.models[x]['accuracy'])
            best_price = predictions[best_model]
            
            st.success(f"**Recommended Prediction:** ‚Çπ{best_price:.2f} Lakhs ({best_model})")

if __name__ == "__main__":
    main()